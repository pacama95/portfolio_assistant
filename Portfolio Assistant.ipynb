{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4af0f672",
   "metadata": {},
   "source": [
    "## Define the Agent state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72092bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Portfolio Assistant with LangGraph - AI Agents System with Tool Routing\n",
    "======================================================================\n",
    "\n",
    "This notebook implements a LangGraph-based AI agents system with:\n",
    "- Agent Node: Analyzes user input and decides when to use tools\n",
    "- Tool Node: Contains all MCP tools and executes them automatically\n",
    "- Conditional Routing: Routes between agent and tools based on AI decisions\n",
    "\n",
    "The system connects to the MCP server and uses langchain-mcp-adapters for native integration.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "# State management\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"State shared between all nodes in the workflow\"\"\"\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    original_user_input: str\n",
    "    execution_plan: AnyMessage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b59ce10",
   "metadata": {},
   "source": [
    "## Define tools\n",
    "- Tools from MCP server (persistence)\n",
    "- Custom tools\n",
    "- Pre-built tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8326f529",
   "metadata": {},
   "source": [
    "### MCP tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4b95734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Connecting to MCP server and loading tools...\n",
      "✅ Successfully loaded 12 LangChain tools from MCP server!\n",
      "\n",
      "📊 Available Portfolio Tools:\n",
      "   1. createTransaction: Create a new transaction in the portfolio.\n",
      "   2. deleteTransaction: Delete a transaction by ID.\n",
      "   3. getAllPositions: Get all current positions in the portfolio.\n",
      "   4. getPortfolioSummary: Get portfolio summary with key metrics.\n",
      "   5. getPositionByTicker: Get position details for a specific ticker.\n",
      "   6. getTransaction: Get a transaction by its ID.\n",
      "   7. getTransactionsByTicker: Get all transactions for a specific ticker.\n",
      "   8. recalculateAllPositions: Recalculate all positions from transactions.\n",
      "   9. recalculatePosition: Recalculate position for a specific ticker.\n",
      "  10. searchTransactions: Search transactions with multiple filters.\n",
      "  11. updateMarketData: Update market data for a position.\n",
      "  12. updateTransaction: Update an existing transaction.\n",
      "\n",
      "🎯 All tools are ready for LangGraph workflow!\n"
     ]
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "mcp_client = MultiServerMCPClient({\n",
    "    \"portfolio\": {\n",
    "        \"url\": \"http://localhost:8081/mcp\",\n",
    "        \"transport\": \"streamable_http\",\n",
    "    }\n",
    "})\n",
    "\n",
    "# Get tools from MCP server - this returns actual LangChain tools!\n",
    "print(\"🔍 Connecting to MCP server and loading tools...\")\n",
    "try:\n",
    "    available_tools = await mcp_client.get_tools()\n",
    "    print(f\"✅ Successfully loaded {len(available_tools)} LangChain tools from MCP server!\")\n",
    "    \n",
    "    print(\"\\n📊 Available Portfolio Tools:\")\n",
    "    for i, tool in enumerate(available_tools, 1):\n",
    "        print(f\"  {i:2d}. {tool.name}: {tool.description}\")\n",
    "    \n",
    "    print(f\"\\n🎯 All tools are ready for LangGraph workflow!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to connect to MCP server: {e}\")\n",
    "    print(\"⚠️  Please ensure the MCP server is running on localhost:8081\")\n",
    "    print(\"   Command: python start_portfolio_http_server.py\")\n",
    "    available_tools = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d295e6c9",
   "metadata": {},
   "source": [
    "### Custom tools for market analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecb2da13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import yfinance as yf\n",
    "from typing import Dict, Any\n",
    "\n",
    "@tool\n",
    "def get_stock_information(symbol: str) -> Dict[str, Any]:\n",
    "    \"\"\" Get current stock price and basic information for a symbol \"\"\"\n",
    "    try:\n",
    "        stock = yf.Ticker(symbol)\n",
    "        info = stock.info\n",
    "        hist = stock.history(period=\"1d\")\n",
    "\n",
    "        if hist.empty:\n",
    "            return {\"error\": f\"No data available for this symbol {symbol}\"}\n",
    "\n",
    "        current_price = hist[\"Close\"].iloc[-1]\n",
    "        return {\n",
    "            \"symbol\": symbol,\n",
    "            \"current_price\": current_price,\n",
    "            \"previous_close\": float(info.get(\"previousClose\", current_price)),\n",
    "            \"volume\": info.get('volume', 0),\n",
    "            \"market_cap\": info.get('marketCap'),\n",
    "            \"day_change\": float(current_price - info.get('previousClose', current_price)),\n",
    "            \"day_change_percent\": float(((current_price - info.get('previousClose', current_price)) / info.get('previousClose', current_price)) * 100) if info.get('previousClose') else 0\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error fetching stock info for {symbol}: {str(e)}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "802fbea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import Dict, Any\n",
    "\n",
    "@tool \n",
    "def calculate_position_value(symbol: str, quantity: float, avg_cost: float, current_price: float) -> Dict[str, Any]:\n",
    "    \"\"\"Calculate the current value and P&L for a stock position\"\"\"\n",
    "    market_value = quantity * current_price\n",
    "    cost_basis = quantity * avg_cost\n",
    "    gain_loss = market_value - cost_basis\n",
    "    gain_loss_percent = (gain_loss / cost_basis) * 100 if cost_basis > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"symbol\": symbol,\n",
    "        \"market_value\": market_value,\n",
    "        \"cost_basis\": cost_basis,\n",
    "        \"gain_loss\": gain_loss,\n",
    "        \"gain_loss_percent\": gain_loss_percent,\n",
    "        \"current_price\": current_price,\n",
    "        \"quantity\": quantity,\n",
    "        \"avg_cost\": avg_cost\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a17c1387",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool\n",
    "def detect_stock_splits(symbol: str, days_back: int = 720) -> Dict[str, Any]:\n",
    "    \"\"\"Detect stock splits for a symbol within specified days back\"\"\"\n",
    "    try:\n",
    "        stock = yf.Ticker(symbol)\n",
    "        splits = stock.splits\n",
    "        \n",
    "        if splits.empty:\n",
    "            return {\"symbol\": symbol, \"splits_found\": False, \"splits\": []}\n",
    "        \n",
    "        # Filter splits within the specified period\n",
    "        from datetime import datetime, timedelta\n",
    "        import pandas as pd\n",
    "        cutoff_date = datetime.now() - timedelta(days=days_back)\n",
    "        # Handle timezone awareness - convert to UTC if splits.index is timezone-aware\n",
    "        if splits.index.tz is not None:\n",
    "            cutoff_date = pd.Timestamp(cutoff_date).tz_localize('UTC')\n",
    "        recent_splits = splits[splits.index >= cutoff_date]\n",
    "        \n",
    "        splits_data = []\n",
    "        for split_date, split_ratio in recent_splits.items():\n",
    "            splits_data.append({\n",
    "                \"date\": split_date.strftime(\"%Y-%m-%d\"),\n",
    "                \"ratio\": float(split_ratio),\n",
    "                \"description\": f\"{int(split_ratio)}:1 split\" if split_ratio >= 1 else f\"1:{int(1/split_ratio)} reverse split\"\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            \"symbol\": symbol,\n",
    "            \"splits_found\": len(splits_data) > 0,\n",
    "            \"splits\": splits_data,\n",
    "            \"total_splits\": len(splits_data)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error detecting splits for {symbol}: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85e516c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculate_position_value_with_splits(\n",
    "    symbol: str, \n",
    "    original_quantity: float, \n",
    "    original_avg_cost: float, \n",
    "    purchase_date: str = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Calculate position value accounting for stock splits since purchase\"\"\"\n",
    "    try:\n",
    "        # Get current stock price\n",
    "        stock_info = get_stock_information(symbol)\n",
    "        if \"error\" in stock_info:\n",
    "            return stock_info\n",
    "        \n",
    "        current_price = stock_info[\"current_price\"]\n",
    "        \n",
    "        # Check for splits since purchase date\n",
    "        if purchase_date:\n",
    "            from datetime import datetime\n",
    "            purchase_dt = datetime.strptime(purchase_date, \"%Y-%m-%d\")\n",
    "            days_since_purchase = (datetime.now() - purchase_dt).days\n",
    "            \n",
    "            splits_info = detect_stock_splits(symbol, days_since_purchase)\n",
    "            \n",
    "            # Apply split adjustments\n",
    "            adjusted_quantity = original_quantity\n",
    "            adjusted_avg_cost = original_avg_cost\n",
    "            \n",
    "            if splits_info[\"splits_found\"]:\n",
    "                cumulative_split_ratio = 1.0\n",
    "                for split in splits_info[\"splits\"]:\n",
    "                    split_date = datetime.strptime(split[\"date\"], \"%Y-%m-%d\")\n",
    "                    if split_date >= purchase_dt:\n",
    "                        cumulative_split_ratio *= split[\"ratio\"]\n",
    "                \n",
    "                adjusted_quantity = original_quantity * cumulative_split_ratio\n",
    "                adjusted_avg_cost = original_avg_cost / cumulative_split_ratio\n",
    "        else:\n",
    "            adjusted_quantity = original_quantity\n",
    "            adjusted_avg_cost = original_avg_cost\n",
    "            splits_info = {\"splits_found\": False, \"splits\": []}\n",
    "        \n",
    "        # Calculate position metrics\n",
    "        market_value = adjusted_quantity * current_price\n",
    "        cost_basis = adjusted_quantity * adjusted_avg_cost\n",
    "        gain_loss = market_value - cost_basis\n",
    "        gain_loss_percent = (gain_loss / cost_basis) * 100 if cost_basis > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            \"symbol\": symbol,\n",
    "            \"original_quantity\": original_quantity,\n",
    "            \"original_avg_cost\": original_avg_cost,\n",
    "            \"current_quantity\": adjusted_quantity,\n",
    "            \"current_avg_cost\": adjusted_avg_cost,\n",
    "            \"current_price\": current_price,\n",
    "            \"market_value\": market_value,\n",
    "            \"cost_basis\": cost_basis,\n",
    "            \"gain_loss\": gain_loss,\n",
    "            \"gain_loss_percent\": gain_loss_percent,\n",
    "            \"splits_applied\": splits_info[\"splits\"],\n",
    "            \"split_adjusted\": splits_info[\"splits_found\"]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error calculating position for {symbol}: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32e2a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def detect_fractional_share_offering(symbol: str, user_paid_price: float) -> Dict[str, Any]:\n",
    "    \"\"\"Detect if broker is offering fractional shares based on price discrepancy\"\"\"\n",
    "    try:\n",
    "        # Get actual market price\n",
    "        stock_info = get_stock_information(symbol)\n",
    "        if \"error\" in stock_info:\n",
    "            return stock_info\n",
    "        \n",
    "        actual_price = stock_info[\"current_price\"]\n",
    "        price_ratio = actual_price / user_paid_price\n",
    "        \n",
    "        # Common fractional ratios\n",
    "        common_ratios = [\n",
    "            2, 3, 4, 5, 6, 8, 10, 12, 15, 16, 20, 25, 30, 32, 40, 50, \n",
    "            60, 64, 75, 80, 100, 120, 125, 150, 160, 200, 250, 300, \n",
    "            400, 500, 600, 750, 800, 1000, 1250, 1500, 2000\n",
    "        ]\n",
    "        \n",
    "        # Find closest ratio\n",
    "        closest_ratio = min(common_ratios, key=lambda x: abs(x - price_ratio))\n",
    "        \n",
    "        # Flexible tolerance - either 10% OR if ratio is > 1.5 (clear fractional indicator)\n",
    "        tolerance_percentage = 0.15 if price_ratio > 1.5 else 0.05  # 15% for likely fractional, 5% for borderline\n",
    "        is_fractional = (\n",
    "            abs(price_ratio - closest_ratio) < (closest_ratio * tolerance_percentage) or \n",
    "            price_ratio > 1.5  # Any ratio > 1.5 is likely fractional\n",
    "        )\n",
    "        \n",
    "        # If no close match found but ratio is high, try to find a reasonable approximation\n",
    "        if not is_fractional and price_ratio > 1.5:\n",
    "            # Round to nearest logical fraction\n",
    "            if price_ratio < 10:\n",
    "                closest_ratio = round(price_ratio)\n",
    "            elif price_ratio < 100:\n",
    "                closest_ratio = round(price_ratio / 5) * 5  # Round to nearest 5\n",
    "            elif price_ratio < 1000:\n",
    "                closest_ratio = round(price_ratio / 10) * 10  # Round to nearest 10\n",
    "            else:\n",
    "                closest_ratio = round(price_ratio / 50) * 50  # Round to nearest 50\n",
    "            \n",
    "            is_fractional = True\n",
    "        \n",
    "        return {\n",
    "            \"symbol\": symbol,\n",
    "            \"actual_price\": actual_price,\n",
    "            \"user_paid_price\": user_paid_price,\n",
    "            \"calculated_ratio\": price_ratio,\n",
    "            \"is_fractional_offering\": is_fractional,\n",
    "            \"estimated_fraction\": 1 / closest_ratio if is_fractional else 1,\n",
    "            \"estimated_ratio\": f\"1:{closest_ratio}\" if is_fractional else \"1:1\",\n",
    "            \"actual_shares_owned\": 1 / closest_ratio if is_fractional else 1,\n",
    "            \"explanation\": f\"You own {1/closest_ratio:.6f} shares of the actual stock\" if is_fractional else \"You own full shares\",\n",
    "            \"confidence\": \"high\" if abs(price_ratio - closest_ratio) < (closest_ratio * 0.05) else \"medium\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error analyzing fractional offering for {symbol}: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14723940",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculate_fractional_position_value(\n",
    "    symbol: str, \n",
    "    broker_quantity: float, \n",
    "    price_paid_per_unit: float\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Calculate position value accounting for fractional share offerings\"\"\"\n",
    "    try:\n",
    "        # Detect if this is a fractional offering\n",
    "        fractional_info = detect_fractional_share_offering(symbol, price_paid_per_unit)\n",
    "        if \"error\" in fractional_info:\n",
    "            return fractional_info\n",
    "        \n",
    "        # Get current market price\n",
    "        stock_info = get_stock_information(symbol)\n",
    "        if \"error\" in stock_info:\n",
    "            return stock_info\n",
    "        \n",
    "        current_actual_price = stock_info[\"current_price\"]\n",
    "        \n",
    "        if fractional_info[\"is_fractional_offering\"]:\n",
    "            # Calculate actual shares owned\n",
    "            fraction_per_unit = fractional_info[\"estimated_fraction\"]\n",
    "            actual_shares_owned = broker_quantity * fraction_per_unit\n",
    "            \n",
    "            # Calculate values\n",
    "            current_market_value = actual_shares_owned * current_actual_price\n",
    "            cost_basis = broker_quantity * price_paid_per_unit\n",
    "            gain_loss = current_market_value - cost_basis\n",
    "            gain_loss_percent = (gain_loss / cost_basis) * 100 if cost_basis > 0 else 0\n",
    "            \n",
    "            return {\n",
    "                \"symbol\": symbol,\n",
    "                \"is_fractional_offering\": True,\n",
    "                \"broker_units_owned\": broker_quantity,\n",
    "                \"actual_shares_owned\": actual_shares_owned,\n",
    "                \"fraction_ratio\": fractional_info[\"estimated_ratio\"],\n",
    "                \"current_actual_share_price\": current_actual_price,\n",
    "                \"price_paid_per_unit\": price_paid_per_unit,\n",
    "                \"current_market_value\": current_market_value,\n",
    "                \"cost_basis\": cost_basis,\n",
    "                \"gain_loss\": gain_loss,\n",
    "                \"gain_loss_percent\": gain_loss_percent,\n",
    "                \"explanation\": f\"Your broker offers 1 unit = {fraction_per_unit:.4f} actual shares\"\n",
    "            }\n",
    "        else:\n",
    "            # Regular calculation\n",
    "            return calculate_position_value(symbol, broker_quantity, price_paid_per_unit, current_actual_price)\n",
    "            \n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error calculating fractional position for {symbol}: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b02033",
   "metadata": {},
   "source": [
    "### Prebuilt tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b0e1e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from tools.youtube_video_transcript import YoutubeVideoTranscriptTool\n",
    "from tools.image_analyzer import ImageAnalyzer\n",
    "from tools.document_question_answering_tool import DocumentQuestionAnsweringTool\n",
    "from tools.youtube_video_transcript import YoutubeVideoTranscriptTool\n",
    "\n",
    "tavily_web_search = TavilySearchResults(max_results=3)\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "youtube_video_transcript = YoutubeVideoTranscriptTool()\n",
    "image_analyzer = ImageAnalyzer()\n",
    "document_question_answering = DocumentQuestionAnsweringTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89364918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='createTransaction', description='Create a new transaction in the portfolio.', args_schema={'type': 'object', 'properties': {'ticker': {'type': 'string', 'description': 'Stock ticker symbol'}, 'type': {'type': 'string', 'description': 'Transaction type (BUY, SELL, DIVIDEND)'}, 'quantity': {'description': 'Quantity of shares'}, 'price': {'description': 'Price per share'}, 'fees': {'description': 'Fees paid per transaction'}, 'isFractional': {'type': 'boolean', 'description': 'Determine if this is an operation on a stock fraction (for fractional offerings)'}, 'fractionalMultiplier': {'description': 'Fraction of the real stock option represented by this fracitonal offered option'}, 'commissionCurrency': {'type': 'string', 'enum': ['USD', 'EUR', 'GBP', 'CAD', 'JPY'], 'description': 'Fees currency'}, 'currency': {'type': 'string', 'enum': ['USD', 'EUR', 'GBP', 'CAD', 'JPY'], 'description': 'Transaction currency'}, 'date': {'type': 'string', 'description': 'Transaction date (YYYY-MM-DD)'}, 'notes': {'type': 'string', 'description': 'Transaction notes (optional)'}}, 'required': ['ticker', 'type', 'quantity', 'price', 'currency', 'date']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x1135d4720>),\n",
       " StructuredTool(name='deleteTransaction', description='Delete a transaction by ID.', args_schema={'type': 'object', 'properties': {'transactionId': {'type': 'string', 'format': 'uuid', 'description': 'The ID of the transaction to delete'}}, 'required': ['transactionId']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x113b5b380>),\n",
       " StructuredTool(name='getAllPositions', description='Get all current positions in the portfolio.', args_schema={'type': 'object', 'properties': {}, 'required': []}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x113b5bba0>),\n",
       " StructuredTool(name='getPortfolioSummary', description='Get portfolio summary with key metrics.', args_schema={'type': 'object', 'properties': {}, 'required': []}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x113b5ba60>),\n",
       " StructuredTool(name='getPositionByTicker', description='Get position details for a specific ticker.', args_schema={'type': 'object', 'properties': {'ticker': {'type': 'string', 'description': 'Stock ticker symbol'}}, 'required': ['ticker']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x113b5b420>),\n",
       " StructuredTool(name='getTransaction', description='Get a transaction by its ID.', args_schema={'type': 'object', 'properties': {'transactionId': {'type': 'string', 'format': 'uuid', 'description': 'The ID of the transaction to retrieve'}}, 'required': ['transactionId']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x113b80900>),\n",
       " StructuredTool(name='getTransactionsByTicker', description='Get all transactions for a specific ticker.', args_schema={'type': 'object', 'properties': {'ticker': {'type': 'string', 'description': 'Stock ticker symbol'}}, 'required': ['ticker']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x113b80a40>),\n",
       " StructuredTool(name='recalculateAllPositions', description='Recalculate all positions from transactions.', args_schema={'type': 'object', 'properties': {}, 'required': []}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x113b80360>),\n",
       " StructuredTool(name='recalculatePosition', description='Recalculate position for a specific ticker.', args_schema={'type': 'object', 'properties': {'ticker': {'type': 'string', 'description': 'Stock ticker symbol'}}, 'required': ['ticker']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x113b805e0>),\n",
       " StructuredTool(name='searchTransactions', description='Search transactions with multiple filters.', args_schema={'type': 'object', 'properties': {'ticker': {'type': 'string', 'description': 'Stock ticker symbol (optional)'}, 'startDate': {'type': 'string', 'description': 'Start date (YYYY-MM-DD, optional)'}, 'endDate': {'type': 'string', 'description': 'End date (YYYY-MM-DD, optional)'}, 'type': {'type': 'string', 'description': 'Transaction type (optional)'}}, 'required': ['ticker', 'startDate', 'endDate', 'type']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x113b80680>),\n",
       " StructuredTool(name='updateMarketData', description='Update market data for a position.', args_schema={'type': 'object', 'properties': {'ticker': {'type': 'string', 'description': 'Stock ticker symbol'}, 'currentPrice': {'description': 'Current market price'}}, 'required': ['ticker', 'currentPrice']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x113b80720>),\n",
       " StructuredTool(name='updateTransaction', description='Update an existing transaction.', args_schema={'type': 'object', 'properties': {'transactionId': {'type': 'string', 'format': 'uuid', 'description': 'Transaction ID to update'}, 'ticker': {'type': 'string', 'description': 'New ticker symbol (optional)'}, 'type': {'type': 'string', 'description': 'New transaction type (optional)'}, 'quantity': {'description': 'New quantity (optional)'}, 'price': {'description': 'New price (optional)'}, 'date': {'type': 'string', 'description': 'New date (YYYY-MM-DD, optional)'}, 'notes': {'type': 'string', 'description': 'New notes (optional)'}}, 'required': ['transactionId', 'ticker', 'type', 'quantity', 'price', 'date', 'notes']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x113b80860>),\n",
       " StructuredTool(name='calculate_position_value', description='Calculate the current value and P&L for a stock position', args_schema=<class 'langchain_core.utils.pydantic.calculate_position_value'>, func=<function calculate_position_value at 0x122ae93a0>),\n",
       " StructuredTool(name='get_stock_information', description='Get current stock price and basic information for a symbol', args_schema=<class 'langchain_core.utils.pydantic.get_stock_information'>, func=<function get_stock_information at 0x113b81620>),\n",
       " StructuredTool(name='calculate_position_value_with_splits', description='Calculate position value accounting for stock splits since purchase', args_schema=<class 'langchain_core.utils.pydantic.calculate_position_value_with_splits'>, func=<function calculate_position_value_with_splits at 0x122ae9620>),\n",
       " StructuredTool(name='detect_stock_splits', description='Detect stock splits for a symbol within specified days back', args_schema=<class 'langchain_core.utils.pydantic.detect_stock_splits'>, func=<function detect_stock_splits at 0x122ae98a0>),\n",
       " StructuredTool(name='detect_fractional_share_offering', description='Detect if broker is offering fractional shares based on price discrepancy', args_schema=<class 'langchain_core.utils.pydantic.detect_fractional_share_offering'>, func=<function detect_fractional_share_offering at 0x122aea200>),\n",
       " StructuredTool(name='calculate_fractional_position_value', description='Calculate position value accounting for fractional share offerings', args_schema=<class 'langchain_core.utils.pydantic.calculate_fractional_position_value'>, func=<function calculate_fractional_position_value at 0x122ae9d00>),\n",
       " TavilySearchResults(max_results=3, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'))),\n",
       " WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/Users/pacama95/venv/lib/python3.13/site-packages/wikipedia/__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=4000)),\n",
       " YoutubeVideoTranscriptTool(),\n",
       " ImageAnalyzer(),\n",
       " DocumentQuestionAnsweringTool()]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_tools.append(calculate_position_value)\n",
    "available_tools.append(get_stock_information)\n",
    "available_tools.append(calculate_position_value_with_splits)\n",
    "available_tools.append(detect_stock_splits)\n",
    "available_tools.append(detect_fractional_share_offering)\n",
    "available_tools.append(calculate_fractional_position_value)\n",
    "available_tools.append(tavily_web_search)\n",
    "available_tools.append(wikipedia)\n",
    "available_tools.append(youtube_video_transcript)\n",
    "available_tools.append(image_analyzer)\n",
    "available_tools.append(document_question_answering)\n",
    "available_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a5d00d",
   "metadata": {},
   "source": [
    "## Define the main LLM and bind tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ec6e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
    "import os\n",
    "\n",
    "rate_limiter = InMemoryRateLimiter(requests_per_second=2, check_every_n_seconds=0.2, max_bucket_size=5)\n",
    "\n",
    "#llm = ChatOllama(model=\"qwen2.5:32b\", num_ctx=32768)\n",
    "#llm = ChatAnthropic(model=\"claude-3-5-haiku-latest\", rate_limiter=rate_limiter)\n",
    "llm = ChatOpenAI(model=\"gpt-4.1\", rate_limiter=rate_limiter)\n",
    "llm_with_tools = llm.bind_tools(available_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb4c445",
   "metadata": {},
   "source": [
    "# Planner node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fc6d306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "#planner_llm = ChatOllama(model=\"qwen2.5:32b\", num_ctx=32768)\n",
    "#planner_llm = ChatAnthropic(model=\"claude-3-5-haiku-latest\")\n",
    "planner_llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "tool_descriptions = []\n",
    "for tool in available_tools:\n",
    "    name = tool.name\n",
    "    desc = tool.description\n",
    "    tool_descriptions.append(f\"- {name}: {desc}\")\n",
    "\n",
    "tools_list_text = \"\\n\".join(tool_descriptions)\n",
    "\n",
    "def planner(state: AgentState):\n",
    "    print(\"\\n----- Running planner -----\\n\")\n",
    "    original_input = state.get(\"original_user_input\", \"\")\n",
    "\n",
    "    system_prompt = (\n",
    "        f\"\"\"\n",
    "        You are a strategic planning agent for a comprehensive portfolio management system. Your role is to analyze user requests and create detailed, step-by-step execution plans to accomplish their goals. You have knowledge of all available tools but CANNOT execute them directly - you only create plans for other agents to follow.\n",
    "        Available Tools in the System:\n",
    "        {tools_list_text}\n",
    "\n",
    "        ## Your Planning Process\n",
    "        For each user request, follow this structured approach:\n",
    "\n",
    "        1. **REQUEST ANALYSIS**: \n",
    "        - Identify the user's primary goal\n",
    "        - Determine required data inputs\n",
    "        - Identify potential risks or edge cases\n",
    "\n",
    "        2. **STEP-BY-STEP PLAN**:\n",
    "        - Break down the request into logical, sequential steps\n",
    "        - Specify which tool should be used for each step\n",
    "        - Include necessary parameters and data flow between steps\n",
    "        - Consider error handling and validation points\n",
    "\n",
    "        3. **DEPENDENCIES & PREREQUISITES**:\n",
    "        - Identify what data must be gathered first\n",
    "        - Note any required validations or checks\n",
    "        - Specify parallel vs sequential execution requirements\n",
    "\n",
    "        4. **SUCCESS CRITERIA**:\n",
    "        - Define what constitutes successful completion\n",
    "        - Specify expected outputs or outcomes\n",
    "        - Include verification steps\n",
    "\n",
    "        ## Planning Guidelines\n",
    "\n",
    "        - **Be Specific**: Name exact tools and parameters needed\n",
    "        - **Consider Data Flow**: Ensure outputs from one step feed properly into the next\n",
    "        - **Include Validation**: Plan for data verification and error checking\n",
    "        - **Think Holistically**: Consider portfolio impact, not just individual transactions\n",
    "        - **Plan for Errors**: Include fallback strategies and rollback procedures\n",
    "        - **Optimize Efficiency**: Suggest parallel execution where appropriate\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    user_prompt = f\"User request: {original_input}\"\n",
    "\n",
    "    try:\n",
    "        plan_message = planner_llm.invoke([\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling to planner LLM: {e}\")\n",
    "        return {\n",
    "            \"original_user_input\": original_input,\n",
    "            \"messages\": state['messages'],\n",
    "            \"execution_plan\": state['execution_plan']\n",
    "        }\n",
    "\n",
    "    plan_user_message = HumanMessage(content=f\"Execution Plan:\\n{plan_message.content}\")\n",
    "\n",
    "    # Combine with existing messages properly\n",
    "    existing_messages = state.get('messages', [])\n",
    "    updated_messages = existing_messages + [plan_user_message]\n",
    "\n",
    "    return {\n",
    "        \"original_user_input\": original_input,\n",
    "        \"messages\": updated_messages,\n",
    "        \"execution_plan\": plan_message\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab659b9f",
   "metadata": {},
   "source": [
    "## Assistant node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b63cb4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Anthropic message sanitization helper loaded\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "def sanitize_messages_for_anthropic(messages):\n",
    "    \"\"\"\n",
    "    Sanitize messages for Anthropic API requirements:\n",
    "    - Only one system message at the beginning\n",
    "    - Convert additional system messages to user messages\n",
    "    - Ensure proper message ordering\n",
    "    \"\"\"\n",
    "    if not messages:\n",
    "        return messages\n",
    "    \n",
    "    # Separate system and non-system messages\n",
    "    system_messages = []\n",
    "    other_messages = []\n",
    "    \n",
    "    for msg in messages:\n",
    "        if isinstance(msg, SystemMessage):\n",
    "            system_messages.append(msg)\n",
    "        else:\n",
    "            other_messages.append(msg)\n",
    "    \n",
    "    # Combine all system content into one system message\n",
    "    if system_messages:\n",
    "        combined_system_content = \"\\n\\n\".join([msg.content for msg in system_messages])\n",
    "        # Only keep the first system message with combined content\n",
    "        sanitized_messages = [SystemMessage(content=combined_system_content)]\n",
    "        sanitized_messages.extend(other_messages)\n",
    "    else:\n",
    "        sanitized_messages = other_messages\n",
    "    \n",
    "    return sanitized_messages\n",
    "\n",
    "print(\"✅ Anthropic message sanitization helper loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbdd3c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def assistant(state: AgentState):\n",
    "    print(\"\\n\\n\\n ----- Running assistant... ----- \\n\\n\\n\")\n",
    "    try:\n",
    "        sanitized_messages = sanitize_messages_for_anthropic(state['messages'])\n",
    "        response = llm_with_tools.invoke(sanitized_messages)\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling to assistant LLM with tools: {e}\")\n",
    "        return {\n",
    "            \"original_user_input\": state[\"original_user_input\"],\n",
    "            \"messages\": state['messages'],\n",
    "            \"execution_plan\": state['execution_plan']\n",
    "        }\n",
    "\n",
    "    print(f\"State: {response}\")\n",
    "    \n",
    "    return {\n",
    "        \"original_user_input\": state[\"original_user_input\"],\n",
    "        \"messages\": state['messages'] + [response],\n",
    "        \"execution_plan\": state['execution_plan']\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe393bd",
   "metadata": {},
   "source": [
    "## Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0fcfeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "tools_node = ToolNode(available_tools)\n",
    "graph_builder.add_node(\"planner\", planner)\n",
    "graph_builder.add_node(\"assistant\", assistant)\n",
    "graph_builder.add_node(\"tools\", tools_node)\n",
    "\n",
    "graph_builder.add_edge(START, \"planner\")\n",
    "graph_builder.add_edge(\"planner\", \"assistant\")\n",
    "graph_builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "graph_builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19899c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png(max_retries=5, retry_delay=3.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11e4c02",
   "metadata": {},
   "source": [
    "## Gradio Integration - Portfolio Assistant Chatbot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "720f0141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Setting up Portfolio Assistant Chatbot with Reset Functionality...\n",
      "✅ Portfolio Assistant is ready!\n",
      "📝 The chatbot interface has been created and is ready to launch.\n",
      "💡 Features included:\n",
      "   - 💬 Full conversation interface\n",
      "   - 🔍 Memory debugging tools\n",
      "   - 🆔 Thread ID tracking\n",
      "   - 📋 Message history viewer\n",
      "   - ⚡ Async tool support for MCP\n",
      "   - 🔄 Working reset conversation functionality\n",
      "💡 Run portfolio_chatbot.launch() to start the interface!\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "import uuid\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "\n",
    "# System prompt for the Portfolio Assistant\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a Portfolio Assistant AI that helps users manage and analyze their investment portfolio. \n",
    "You have access to a comprehensive set of portfolio management tools that allow you to:\n",
    "\n",
    "📊 **Portfolio Analysis:**\n",
    "- View all current positions and portfolio summary\n",
    "- Get performance metrics and analytics\n",
    "- Analyze specific ticker investments\n",
    "\n",
    "💼 **Transaction Management:**\n",
    "- Create, update, and delete transactions\n",
    "- Search transactions by various criteria\n",
    "- View transaction history for specific tickers\n",
    "\n",
    "💰 **Position Management:**\n",
    "- Get detailed position information\n",
    "- Update market data and current prices\n",
    "- Recalculate positions when needed\n",
    "\n",
    "🔍 **Data & Insights:**\n",
    "- Search and filter portfolio data\n",
    "- Get comprehensive ticker analysis\n",
    "- Monitor portfolio performance over time\n",
    "- Detect stock splits, if any position shows a big difference in cost per share compared to the current market price (e.g. more than 100% difference), be suspicious and ask the user to check the splits\n",
    "- Detect if broker is offering fractional shares based on price discrepancy when market price is much higher than the user paid price (e.g. more than 100% difference)\n",
    "\"\"\"\n",
    "\n",
    "# Global variable to store the current thread_id for debugging\n",
    "current_thread_id = None\n",
    "\n",
    "def format_message_for_debug(msg, index):\n",
    "    \"\"\"Format a single message for readable display\"\"\"\n",
    "    msg_type = type(msg).__name__\n",
    "    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    \n",
    "    if hasattr(msg, 'content'):\n",
    "        content = msg.content\n",
    "    else:\n",
    "        content = str(msg)\n",
    "    \n",
    "    # Handle tool calls if present\n",
    "    tool_info = \"\"\n",
    "    if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "        tool_info = f\"\\n   🔧 Tool Calls: {[tc.get('name', 'Unknown') for tc in msg.tool_calls]}\"\n",
    "    \n",
    "    return f\"\"\"\n",
    "┌─ Message {index + 1}: {msg_type} [{timestamp}]\n",
    "│  📝 Content: {content}\n",
    "│  🏷️  Additional: {getattr(msg, 'additional_kwargs', {})}{tool_info}\n",
    "└─ \"\"\"\n",
    "\n",
    "async def get_graph_memory_debug_async(thread_id_input=None):\n",
    "    \"\"\"Retrieve and format all messages from graph memory for debugging (async version)\"\"\"\n",
    "    try:\n",
    "        # Use provided thread_id or current one\n",
    "        debug_thread_id = thread_id_input.strip() if thread_id_input else current_thread_id\n",
    "        \n",
    "        if not debug_thread_id:\n",
    "            return \"❌ No thread ID available. Start a conversation first or provide a thread ID.\"\n",
    "        \n",
    "        # Get state from graph memory\n",
    "        config = {\"configurable\": {\"thread_id\": debug_thread_id}}\n",
    "        \n",
    "        try:\n",
    "            state = await graph.aget_state(config)  # Use async version\n",
    "            \n",
    "            if not state or not state.values:\n",
    "                return f\"📭 No state found for thread ID: {debug_thread_id}\"\n",
    "            \n",
    "            messages = state.values.get(\"messages\", [])\n",
    "            original_input = state.values.get(\"original_user_input\", \"N/A\")\n",
    "            execution_plan = state.values.get(\"execution_plan\", \"N/A\")\n",
    "            \n",
    "            # Format output\n",
    "            debug_output = f\"\"\"\n",
    "🔍 LANGGRAPH MEMORY DEBUG\n",
    "═══════════════════════════════════════════════════════════════\n",
    "\n",
    "🆔 Thread ID: {debug_thread_id}\n",
    "📋 Original Input: {original_input}\n",
    "💬 Total Messages: {len(messages)}\n",
    "📝 Execution Plan: {type(execution_plan).__name__ if execution_plan else \"None\"}\n",
    "\n",
    "📨 MESSAGE HISTORY:\n",
    "═══════════════════════════════════════════════════════════════\n",
    "\"\"\"\n",
    "            \n",
    "            if messages:\n",
    "                for i, msg in enumerate(messages):\n",
    "                    debug_output += format_message_for_debug(msg, i)\n",
    "            else:\n",
    "                debug_output += \"\\n📭 No messages found in memory.\"\n",
    "            \n",
    "            debug_output += f\"\"\"\n",
    "═══════════════════════════════════════════════════════════════\n",
    "\n",
    "🔧 GRAPH STATE SUMMARY:\n",
    "- State Keys: {list(state.values.keys()) if state.values else \"None\"}\n",
    "- Next Node: {state.next or \"END\"}\n",
    "- Config: {state.config}\n",
    "\n",
    "🕒 Last Updated: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "═══════════════════════════════════════════════════════════════\n",
    "\"\"\"\n",
    "            \n",
    "            return debug_output\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"❌ Error accessing graph state: {str(e)}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"❌ Debug error: {str(e)}\"\n",
    "\n",
    "def get_graph_memory_debug(thread_id_input=None):\n",
    "    \"\"\"Sync wrapper for the async debug function\"\"\"\n",
    "    try:\n",
    "        # Create new event loop for this sync function\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "        try:\n",
    "            return loop.run_until_complete(get_graph_memory_debug_async(thread_id_input))\n",
    "        finally:\n",
    "            loop.close()\n",
    "    except Exception as e:\n",
    "        return f\"❌ Debug error: {str(e)}\"\n",
    "\n",
    "def reset_conversation():\n",
    "    \"\"\"Reset the conversation thread and clear chat UI\"\"\"\n",
    "    global current_thread_id\n",
    "    old_thread_id = current_thread_id\n",
    "    current_thread_id = str(uuid.uuid4())\n",
    "    \n",
    "    status_message = f\"\"\"🔄 Conversation Reset Complete!\n",
    "\n",
    "📋 Details:\n",
    "• Previous Thread ID: {old_thread_id or 'None'}\n",
    "• New Thread ID: {current_thread_id}\n",
    "• Chat history cleared\n",
    "• Fresh conversation started\n",
    "\n",
    "💡 You can now start a new conversation with a clean slate!\"\"\"\n",
    "    \n",
    "    return status_message, None  # Return status and None to clear chat\n",
    "\n",
    "async def chat_with_portfolio_assistant(message, history):\n",
    "    \"\"\"\n",
    "    Handle chat interaction with the Portfolio Assistant (SIMPLIFIED VERSION)\n",
    "    \"\"\"\n",
    "    global current_thread_id\n",
    "    \n",
    "    try:\n",
    "        # Use persistent thread ID for the conversation\n",
    "        if current_thread_id is None:\n",
    "            current_thread_id = str(uuid.uuid4())\n",
    "        \n",
    "        config = {\"configurable\": {\"thread_id\": current_thread_id}}\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=SYSTEM_PROMPT),\n",
    "            HumanMessage(content=message)\n",
    "        ]\n",
    "        \n",
    "        # Prepare initial state\n",
    "        initial_state = {\n",
    "            \"messages\": messages,\n",
    "            \"original_user_input\": message,\n",
    "            \"execution_plan\": \"\"\n",
    "        }\n",
    "        \n",
    "        # Use ASYNC invocation for MCP tools compatibility\n",
    "        print(f\"🔄 Processing request: {message[:50]}...\")\n",
    "        print(f\"🆔 Thread ID: {current_thread_id}\")\n",
    "        \n",
    "        # Use ainvoke for async tools\n",
    "        final_state = await graph.ainvoke(initial_state, config=config)\n",
    "        \n",
    "        # Extract the assistant's response\n",
    "        response_content = \"\"\n",
    "        if final_state.get(\"messages\"):\n",
    "            # Find the last AI message\n",
    "            for msg in reversed(final_state[\"messages\"]):\n",
    "                if hasattr(msg, 'content') and isinstance(msg, AIMessage):\n",
    "                    response_content = clean_llm_response(msg.content)\n",
    "                    break\n",
    "        \n",
    "        if not response_content:\n",
    "            return \"I apologize, but I encountered an issue processing your request. Please try again.\"\n",
    "        \n",
    "        print(f\"✅ Response ready ({len(response_content)} chars)\")\n",
    "        return response_content\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in chat function: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return f\"I encountered an error: {str(e)}. Please try your request again.\"\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_llm_response(response: str) -> str:\n",
    "    \"\"\"Remove thinking sections that break Gradio display\"\"\"\n",
    "    \n",
    "    # Remove common thinking section patterns\n",
    "    patterns = [\n",
    "        r'<thinking>.*?</thinking>',\n",
    "        r'<think>.*?</think>',\n",
    "        r'<thought>.*?</thought>', \n",
    "        r'<reasoning>.*?</reasoning>',\n",
    "        r'\\[thinking\\].*?\\[/thinking\\]',\n",
    "        r'<!--.*?thinking.*?-->'\n",
    "    ]\n",
    "    \n",
    "    cleaned = response\n",
    "    for pattern in patterns:\n",
    "        cleaned = re.sub(pattern, '', cleaned, flags=re.DOTALL | re.IGNORECASE)\n",
    "    \n",
    "    # Clean up extra whitespace\n",
    "    cleaned = re.sub(r'\\n\\s*\\n\\s*\\n', '\\n\\n', cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    \n",
    "    # Return fallback if empty\n",
    "    return cleaned if cleaned else \"Response processed successfully.\"\n",
    "\n",
    "# Create Gradio interface\n",
    "def create_portfolio_chatbot():\n",
    "    \"\"\"\n",
    "    Create and configure the Gradio chatbot interface with debug functionality\n",
    "    \"\"\"\n",
    "    \n",
    "    with gr.Blocks(\n",
    "        title=\"Portfolio Assistant\", \n",
    "        theme=gr.themes.Soft(),\n",
    "        css=\"\"\"\n",
    "        .gradio-container {\n",
    "            max-width: 1400px !important;\n",
    "        }\n",
    "        .chat-message {\n",
    "            border-radius: 10px !important;\n",
    "        }\n",
    "        .debug-section {\n",
    "            border: 2px solid #e1e5e9;\n",
    "            border-radius: 8px;\n",
    "            padding: 10px;\n",
    "            margin: 10px 0;\n",
    "        }\n",
    "        \"\"\"\n",
    "    ) as interface:\n",
    "        \n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            # 📈 Portfolio Assistant\n",
    "            \n",
    "            Welcome to your AI-powered Portfolio Assistant! I can help you manage and analyze your investment portfolio using advanced tools and real-time data.\n",
    "            \n",
    "            **What I can help you with:**\n",
    "            - 📊 Portfolio analysis and performance metrics\n",
    "            - 💼 Transaction management (create, update, delete)\n",
    "            - 💰 Position tracking and market data updates\n",
    "            - 🔍 Advanced search and filtering\n",
    "            - 📈 Investment insights and recommendations\n",
    "            \n",
    "            **💬 Chat with your Portfolio Assistant below:**\n",
    "            Ask me anything about your portfolio - I have access to all your investment data!\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        # Main chat interface\n",
    "        chatbot_interface = gr.ChatInterface(\n",
    "            fn=chat_with_portfolio_assistant,\n",
    "            examples=[\n",
    "                \"What's my current portfolio summary?\",\n",
    "                \"Show me all my transactions for AAPL\",\n",
    "                \"Add a buy transaction: 50 shares of MSFT at $350 on 2024-01-15\",\n",
    "                \"What are my performance metrics?\",\n",
    "                \"Update Tesla's current price to $245\",\n",
    "                \"What's my position in Apple stock?\",\n",
    "                \"Search for all transactions in the last 30 days\"\n",
    "            ],\n",
    "            type=\"messages\"\n",
    "        )\n",
    "        \n",
    "        # Debug section\n",
    "        gr.Markdown(\"---\")\n",
    "        gr.Markdown(\"## 🔍 Debug & Control Tools\", elem_classes=[\"debug-section\"])\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=2):\n",
    "                thread_id_input = gr.Textbox(\n",
    "                    label=\"🆔 Thread ID (optional)\",\n",
    "                    placeholder=\"Leave empty to use current conversation thread\",\n",
    "                    info=\"Enter a specific thread ID to debug, or leave empty to debug current conversation\"\n",
    "                )\n",
    "            \n",
    "            with gr.Column(scale=1):\n",
    "                with gr.Row():\n",
    "                    debug_btn = gr.Button(\"🔍 View Memory\", variant=\"secondary\")\n",
    "                    reset_btn = gr.Button(\"🔄 Reset Conversation\", variant=\"stop\")\n",
    "        \n",
    "        # Status output for reset\n",
    "        reset_status = gr.Textbox(\n",
    "            label=\"🔄 Reset Status\",\n",
    "            placeholder=\"Click 'Reset Conversation' to start fresh...\",\n",
    "            lines=6,\n",
    "            show_copy_button=False,\n",
    "            elem_classes=[\"debug-section\"]\n",
    "        )\n",
    "        \n",
    "        # Debug output area\n",
    "        debug_output = gr.Textbox(\n",
    "            label=\"📋 Graph Memory Debug Output\",\n",
    "            placeholder=\"Click 'View Memory' to see the current graph state and message history...\",\n",
    "            lines=20,\n",
    "            max_lines=30,\n",
    "            show_copy_button=True,\n",
    "            elem_classes=[\"debug-section\"]\n",
    "        )\n",
    "        \n",
    "        # Current thread ID display\n",
    "        current_thread_display = gr.Textbox(\n",
    "            label=\"🆔 Current Thread ID\",\n",
    "            value=lambda: current_thread_id or \"No active conversation\",\n",
    "            interactive=False\n",
    "        )\n",
    "        \n",
    "        # Wire up the functionality\n",
    "        debug_btn.click(\n",
    "            fn=get_graph_memory_debug,\n",
    "            inputs=[thread_id_input],\n",
    "            outputs=[debug_output]\n",
    "        )\n",
    "        \n",
    "        # ✅ FIXED: Reset conversation properly\n",
    "        reset_btn.click(\n",
    "            fn=reset_conversation,\n",
    "            inputs=[],\n",
    "            outputs=[reset_status, chatbot_interface.chatbot]  # Clear both status and chat\n",
    "        ).then(\n",
    "            fn=lambda: current_thread_id or \"No active conversation\",\n",
    "            inputs=[],\n",
    "            outputs=[current_thread_display]  # Update thread ID display\n",
    "        )\n",
    "        \n",
    "        # Add footer information\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            ---\n",
    "            \n",
    "            **💡 Tips:**\n",
    "            - Be specific when adding transactions (include ticker, quantity, price, date)\n",
    "            - Ask for summaries to get quick overviews\n",
    "            - Use ticker symbols (e.g., AAPL, MSFT, TSLA) for best results\n",
    "            - I can handle multiple requests in one message\n",
    "            \n",
    "            **🔧 Tools Available:** Transaction Management, Portfolio Analysis, Position Tracking, Performance Metrics, Market Data Updates\n",
    "            \n",
    "            **🔍 Debug & Control Tools:**\n",
    "            - **View Memory**: See all messages and state in the current conversation thread\n",
    "            - **Reset Conversation**: Clear chat history and start with a new thread ID\n",
    "            - **Thread ID**: Each conversation gets a unique ID for memory isolation\n",
    "            \"\"\"\n",
    "        )\n",
    "    \n",
    "    return interface\n",
    "\n",
    "# Create and launch the chatbot\n",
    "print(\"🚀 Setting up Portfolio Assistant Chatbot with Reset Functionality...\")\n",
    "portfolio_chatbot = create_portfolio_chatbot()\n",
    "\n",
    "print(\"✅ Portfolio Assistant is ready!\")\n",
    "print(\"📝 The chatbot interface has been created and is ready to launch.\")\n",
    "print(\"💡 Features included:\")\n",
    "print(\"   - 💬 Full conversation interface\")\n",
    "print(\"   - 🔍 Memory debugging tools\")\n",
    "print(\"   - 🆔 Thread ID tracking\")\n",
    "print(\"   - 📋 Message history viewer\")\n",
    "print(\"   - ⚡ Async tool support for MCP\")\n",
    "print(\"   - 🔄 Working reset conversation functionality\")\n",
    "print(\"💡 Run portfolio_chatbot.launch() to start the interface!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "457f6297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Starting Portfolio Assistant Chatbot...\n",
      "🔗 Make sure your MCP server is running on localhost:8081\n",
      "📡 Launching Gradio interface...\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"800\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Processing request: What's my current portfolio summary?...\n",
      "🆔 Thread ID: db6b28e3-d322-432b-9221-d6ad832e06e5\n",
      "\n",
      "----- Running planner -----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ----- Running assistant... ----- \n",
      "\n",
      "\n",
      "\n",
      "State: content='' additional_kwargs={'tool_calls': [{'id': 'call_WqJmbhFEn62eGJyKeh1m2JHl', 'function': {'arguments': '{}', 'name': 'recalculateAllPositions'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 1911, 'total_tokens': 1923, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_51e1070cf2', 'id': 'chatcmpl-Bymm3Zqt8GCRCITAKOC4PsIpqmFtg', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--0784ff6d-9b8d-43c9-b4c0-ffac9af84f28-0' tool_calls=[{'name': 'recalculateAllPositions', 'args': {}, 'id': 'call_WqJmbhFEn62eGJyKeh1m2JHl', 'type': 'tool_call'}] usage_metadata={'input_tokens': 1911, 'output_tokens': 12, 'total_tokens': 1923, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "\n",
      "\n",
      "\n",
      " ----- Running assistant... ----- \n",
      "\n",
      "\n",
      "\n",
      "State: content='' additional_kwargs={'tool_calls': [{'id': 'call_QXVO9PWg5tPmF9Xek9XCA59A', 'function': {'arguments': '{}', 'name': 'getPortfolioSummary'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 1939, 'total_tokens': 1950, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1792}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_51e1070cf2', 'id': 'chatcmpl-Bymm5yWvbHwXoBLYckhcNmE4WApxb', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--1bf3cfcf-938a-4774-863b-59410a6dabbf-0' tool_calls=[{'name': 'getPortfolioSummary', 'args': {}, 'id': 'call_QXVO9PWg5tPmF9Xek9XCA59A', 'type': 'tool_call'}] usage_metadata={'input_tokens': 1939, 'output_tokens': 11, 'total_tokens': 1950, 'input_token_details': {'audio': 0, 'cache_read': 1792}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "\n",
      "\n",
      "\n",
      " ----- Running assistant... ----- \n",
      "\n",
      "\n",
      "\n",
      "State: content=\"Your current portfolio summary shows no holdings or activity. All main portfolio metrics are as follows:\\n\\n- Total Market Value: $0\\n- Total Cost: $0\\n- Total Unrealized Gain/Loss: $0 (0%)\\n- Number of Positions: 0 (Active Positions: 0)\\n\\nIt appears there are no investments or recorded transactions in your portfolio at this time. If you believe this is incorrect, please let me know if you'd like to review transaction history or add new investments.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 2000, 'total_tokens': 2100, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1920}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_51e1070cf2', 'id': 'chatcmpl-Bymm703KZbGiCh7ynFU6WL29G536Y', 'finish_reason': 'stop', 'logprobs': None} id='run--7cec90d5-2704-4941-8afa-24d03502759e-0' usage_metadata={'input_tokens': 2000, 'output_tokens': 100, 'total_tokens': 2100, 'input_token_details': {'audio': 0, 'cache_read': 1920}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "✅ Response ready (447 chars)\n",
      "🔄 Processing request: I have just bought a 100 Apple stock for 200 USD...\n",
      "🆔 Thread ID: db6b28e3-d322-432b-9221-d6ad832e06e5\n",
      "\n",
      "----- Running planner -----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ----- Running assistant... ----- \n",
      "\n",
      "\n",
      "\n",
      "State: content='' additional_kwargs={'tool_calls': [{'id': 'call_kA30naPRpJj4TDxIpqTHaO4F', 'function': {'arguments': '{\"ticker\":\"AAPL\",\"type\":\"BUY\",\"quantity\":100,\"price\":200,\"currency\":\"USD\",\"date\":\"2024-06-13\"}', 'name': 'createTransaction'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 2941, 'total_tokens': 2981, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_51e1070cf2', 'id': 'chatcmpl-Bymn2PzfxPv82L2uDaWu47wXHJ39B', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--e7e75483-8770-4db1-bda9-74d709a3fcb6-0' tool_calls=[{'name': 'createTransaction', 'args': {'ticker': 'AAPL', 'type': 'BUY', 'quantity': 100, 'price': 200, 'currency': 'USD', 'date': '2024-06-13'}, 'id': 'call_kA30naPRpJj4TDxIpqTHaO4F', 'type': 'tool_call'}] usage_metadata={'input_tokens': 2941, 'output_tokens': 40, 'total_tokens': 2981, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "\n",
      "\n",
      "\n",
      " ----- Running assistant... ----- \n",
      "\n",
      "\n",
      "\n",
      "State: content=\"There was an internal error while trying to record your Apple stock transaction. This could be a temporary system issue.\\n\\nWould you like to try again, or provide any additional details (such as fees or notes) before I attempt to create the transaction again? Let me know how you'd like to proceed.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 3029, 'total_tokens': 3089, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2944}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_51e1070cf2', 'id': 'chatcmpl-Bymn47XeSNV5Ugr0rbHOcwajI0X29', 'finish_reason': 'stop', 'logprobs': None} id='run--1938c010-799b-43a3-ac33-a18b7c5683f6-0' usage_metadata={'input_tokens': 3029, 'output_tokens': 60, 'total_tokens': 3089, 'input_token_details': {'audio': 0, 'cache_read': 2944}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "✅ Response ready (297 chars)\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    }
   ],
   "source": [
    "# Launch the Portfolio Assistant Chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🎯 Starting Portfolio Assistant Chatbot...\")\n",
    "    print(\"🔗 Make sure your MCP server is running on localhost:8081\")\n",
    "    print(\"📡 Launching Gradio interface...\")\n",
    "    \n",
    "    # Launch with share=False for local use, set share=True to create public link\n",
    "    portfolio_chatbot.launch(\n",
    "        server_name=\"127.0.0.1\",  # Local access only\n",
    "        server_port=7860,         # Default Gradio port\n",
    "        share=False,              # Set to True for public sharing\n",
    "        debug=True,               # Enable debug mode\n",
    "        show_error=True,          # Show detailed error messages\n",
    "        quiet=False,              # Show startup logs\n",
    "        inbrowser=True,           # Auto-open in browser\n",
    "        height=800,               # Interface height\n",
    "        favicon_path=None,        # You can add a custom favicon\n",
    "        auth=None,                # Add authentication if needed: auth=(\"username\", \"password\")\n",
    "    )\n",
    "else:\n",
    "    print(\"📝 To launch the chatbot, run: portfolio_chatbot.launch()\")\n",
    "    print(\"💡 Example: portfolio_chatbot.launch(share=True) for public access\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
